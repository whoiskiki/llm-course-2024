# Домашнее задание 1: "Введение в языковое моделирование"

## Описание

Цель данного домашнего задания — реализовать и обучить модель для генерации гороскопов на основе архитектуры LSTM. Нужно дополнить код, предоставленный в проекте, в ключевых местах и пройти все unit-тесты. Задание подразумевает знакомство с процессом обучения языковых моделей и основными компонентами нейросетевого пайплайна: от токенизации до генерации текста.

Для успешного выполнения задания, необходимо:

1. Реализовать BPE-токенизатор.
2. Реализовать набор данных (Dataset), коллатор (Collator) и класс для модели (nn.Module).
3. Реализовать обучение модели с помощью Trainer.
4. Написать функцию генерации текста с поддержкой жадной и случайной генерации (с параметрами температуры и top-k).

Задание будет считаться выполненным, если будут пройдены все unit-тесты. Тесты расположены в папке `tests` и запускаются командой:

```bash
python -m unittest tests/*.py
```

## Структура проекта

- **`scripts`** — файлы с кодом, который вам нужно дописать.
- **`tests`** — unit-тесты.
- **`homework.ipynb`** - ноутбук, в котором представлен пайплайн обучения модели с использованием написанной вами кодовой базы. Этот ноутбук поможет вам визуализировать процесс обучения и результат генерации текста.


## Порядок выполнения

### 1. Реализация BPE-токенизатора

Начните с реализации класса `BpeTokenizer`. Этот токенизатор должен уметь:

- Обучаться на корпусе текста, разбивая его на токены с использованием Byte Pair Encoding.
- Токенизировать текст.
- Декодировать токены обратно в текст.

### 2. Реализация Dataset

Следующим шагом реализуйте класс `Dataset`. Этот модуль должен уметь:

- Загружать и обрабатывать датасет.
- Преобразовывать текст в токены для подачи в модель.

### 3. Реализация Collator

Реализуйте collator для формирования мини-батчей. Collator должен:

- Объединять последовательности разной длины в батчи.
- Учитывать padding при формировании батчей для обеспечения корректной работы LSTM.

### 4. Реализация Model

Создайте нейросетевую модель для генерации текста на основе LSTM. Основные требования:

- Модель должна предсказывать следующий токен на основе предыдущих.
- Использовать рекуррентные слои (LSTM) и линейные слои для предсказания токенов.

### 5. Реализация Trainer

Реализуйте класс `Trainer`, который будет отвечать за процесс обучения модели. Основные задачи:

- Обучение модели на тренировочных данных.
- Валидация модели на валидационных данных.
- Логирование процесса обучения.

### 6. Реализация функции генерации текста

Напишите функцию `generate`, которая должна поддерживать два режима генерации текста:

- **Жадная генерация**: выбирается наиболее вероятный следующий токен.
- **Случайная генерация**: выбор следующего токена происходит случайным образом с учетом температуры и параметра `top_k`.


## Требования

- Python 3.9
- PyTorch 2.0.1
- numpy
- tqdm

Установить зависимости можно с помощью команды:

```bash
pip install -r requirements.txt
```

## Заключение

Этот проект научит вас основным этапам разработки и обучения нейросетей для обработки текста. В процессе выполнения задания вы освоите важные техники работы с текстовыми данными, а также принципы работы рекуррентных сетей и генерации текста.

Удачи в выполнении задания!